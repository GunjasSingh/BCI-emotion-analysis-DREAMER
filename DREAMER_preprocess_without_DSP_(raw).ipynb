{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DREAMER preprocess without DSP (raw).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM72dKUAuMX455Oh67EmSn5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxSgleo8xSp6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "6c221085-6911-45cc-9dab-cc17be117619"
      },
      "source": [
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn import svm\n",
        "from scipy import signal\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "\n",
        "!pip install neurokit2\n",
        "import neurokit2 as nk\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "!pip install mne\n",
        "import mne"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: neurokit2 in /usr/local/lib/python3.6/dist-packages (0.0.40)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from neurokit2) (1.4.1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from neurokit2) (0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from neurokit2) (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from neurokit2) (1.0.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from neurokit2) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->neurokit2) (0.22.2.post1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->neurokit2) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->neurokit2) (2018.9)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->neurokit2) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->neurokit2) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->neurokit2) (1.2.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->neurokit2) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->neurokit2) (1.15.0)\n",
            "Requirement already satisfied: mne in /usr/local/lib/python3.6/dist-packages (0.20.7)\n",
            "Requirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mne) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from mne) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK8IW_yt2GHi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "7d28cd33-d54d-4fcb-ef4a-5e9a4b935e76"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_J6l62p1D3e"
      },
      "source": [
        "path = \"/content/drive/My Drive/DREAMERedit.mat\"\n",
        "raw = sio.loadmat(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IX8dPUbyrSJ"
      },
      "source": [
        "#Step 1 : frames\n",
        "\n",
        "\n",
        "def preprocess_EEG(raw, feature):\n",
        " \n",
        "  frame =[]\n",
        "  #Dividing into frames\n",
        "  \n",
        "  for i in range(0,7680):\n",
        "    j = i//640\n",
        "    k = i%640\n",
        "    frame[j][k] = raw[i]\n",
        "  \n",
        "  #frame[0][0-639] - Frame 1, frame[11][0-639] - Frame 12\n",
        "    fe=[]\n",
        "    fe.append(deltamean[i])\n",
        "    fe.append(thetamean[i])\n",
        "    fe.append(alphamean[i])\n",
        "    fe.append(betamean[i])\n",
        "    fe.append(gammamean[i])\n",
        "      \n",
        "    feature.append(fe)\n",
        "\n",
        "  return feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSluSMuW6Hvw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05bac696-3db3-4c76-b4a8-97cf005e404a"
      },
      "source": [
        "participant =0\n",
        "video = 0\n",
        "electrode = 0\n",
        "B, S = [], []\n",
        "                \n",
        "basl = (raw[\"DREAMER\"][0, 0][\"Data\"][0, participant][\"EEG\"][0, 0][\"baseline\"][0, 0][video, 0][:, electrode])\n",
        "stim = (raw[\"DREAMER\"][0, 0][\"Data\"][0, participant][\"EEG\"][0, 0][\"stimuli\"][0, 0][video, 0][:, electrode])\n",
        "                \n",
        "#B = preprocess_EEG(basl, B) \n",
        "#S = preprocess_EEG(stim, S)\n",
        "stim.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7680,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyYxLLolx1uA"
      },
      "source": [
        "def feat_extract_EEG(raw):\n",
        "    \n",
        "    EEG_tmp = np.zeros((23, 18, 107520))\n",
        "    for participant in range(0, 23):\n",
        "        for video in range(0, 18):\n",
        "          column=0\n",
        "          for electrode in range(0,14):\n",
        "            stim = (raw[\"DREAMER\"][0, 0][\"Data\"][0, participant][\"EEG\"][0, 0][\"stimuli\"][0, 0][video, 0][:, electrode])\n",
        "            for i in range(0,7680):\n",
        "              EEG_tmp[participant,video,column]= stim[i]\n",
        "              column+=1\n",
        "                                \n",
        "\n",
        "    col = []\n",
        "\n",
        "    for i in range(0, 7680):\n",
        "      col.append(\"Electrode1_\"+str(i + 1))\n",
        "    for i in range(0, 7680):\n",
        "      col.append(\"Electrode2_\"+str(i + 1))\n",
        "    for i in range(0, 7680):\n",
        "      col.append(\"Electrode3_\"+str(i + 1))\n",
        "    for i in range(0, 7680):\n",
        "     col.append(\"Electrode4_\"+str(i + 1))\n",
        "    for i in range(0, 7680):\n",
        "      col.append(\"Electrode5_\"+str(i + 1))\n",
        "    for i in range(0, 7680):\n",
        "      col.append(\"Electrode6_\"+str(i + 1))\n",
        "    for i in range(0, 7680):\n",
        "      col.append(\"Electrode7_\"+str(i + 1))\n",
        "    for i in range(0, 7680):\n",
        "      col.append(\"Electrode8_\"+str(i + 1))\n",
        "    for i in range(0, 7680):\n",
        "     col.append(\"Electrode9_\"+str(i + 1))\n",
        "    for i in range(0, 7680):\n",
        "      col.append(\"Electrode10_\"+str(i + 1))\n",
        "    for i in range(0, 7680):\n",
        "      col.append(\"Electrode11_\"+str(i + 1))\n",
        "    for i in range(0, 7680):\n",
        "      col.append(\"Electrode12_\"+str(i + 1))\n",
        "    for i in range(0, 7680):\n",
        "      col.append(\"Electrode13_\"+str(i + 1))\n",
        "    for i in range(0, 7680):\n",
        "     col.append(\"Electrode14_\"+str(i + 1))\n",
        "\n",
        "\n",
        "    EEG_tmp = EEG_tmp.reshape(-1,EEG_tmp.shape[2])\n",
        "    data_EEG = pd.DataFrame(EEG_tmp, columns=col)\n",
        "    print(data_EEG)\n",
        "    from sklearn import preprocessing\n",
        "\n",
        "    x = data_EEG.values\n",
        "    min_max_scaler = preprocessing.MinMaxScaler()\n",
        "    x_scaled = min_max_scaler.fit_transform(x)\n",
        "    data_EEG = pd.DataFrame(x_scaled)\n",
        "    data_EEG.columns = col\n",
        "    print(data_EEG)\n",
        "    return data_EEG"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrRPtLU_x1uC"
      },
      "source": [
        "def participant_affective(raw):\n",
        "    a = np.zeros((23, 18, 9), dtype=object)\n",
        "    for participant in range(0, 23):\n",
        "        for video in range(0, 18):\n",
        "            a[participant, video, 0] = (raw[\"DREAMER\"][0, 0][\"Data\"]\n",
        "                                        [0, participant][\"Age\"][0][0][0])\n",
        "            \n",
        "            a[participant, video, 1] = (raw[\"DREAMER\"][0, 0][\"Data\"]\n",
        "                                        [0, participant][\"Gender\"][0][0][0])\n",
        "            \n",
        "            a[participant, video, 2] = int(participant+1)\n",
        "            \n",
        "            a[participant, video, 3] = int(video+1)\n",
        "            \n",
        "            a[participant, video, 4] = [\"Searching for Bobby Fischer\",\n",
        "                                        \"D.O.A.\", \"The Hangover\", \"The Ring\",\n",
        "                                        \"300\", \"National Lampoon\\'s VanWilder\",\n",
        "                                        \"Wall-E\", \"Crash\", \"My Girl\",\n",
        "                                        \"The Fly\", \"Pride and Prejudice\",\n",
        "                                        \"Modern Times\", \"Remember the Titans\",\n",
        "                                        \"Gentlemans Agreement\", \"Psycho\",\n",
        "                                        \"The Bourne Identitiy\",\n",
        "                                        \"The Shawshank Redemption\",\n",
        "                                        \"The Departed\"][video]\n",
        "            \n",
        "            a[participant, video, 5] = [\"calmness\", \"surprise\", \"amusement\",\n",
        "                                        \"fear\", \"excitement\", \"disgust\",\n",
        "                                        \"happiness\", \"anger\", \"sadness\",\n",
        "                                        \"disgust\", \"calmness\", \"amusement\",\n",
        "                                        \"happiness\", \"anger\", \"fear\",\n",
        "                                        \"excitement\", \"sadness\",\n",
        "                                        \"surprise\"][video]\n",
        "            a[participant, video, 6] = int(raw[\"DREAMER\"][0, 0][\"Data\"]\n",
        "                                           [0, participant][\"ScoreValence\"]\n",
        "                                           [0, 0][video, 0])\n",
        "            a[participant, video, 7] = int(raw[\"DREAMER\"][0, 0][\"Data\"]\n",
        "                                           [0, participant][\"ScoreArousal\"]\n",
        "                                           [0, 0][video, 0])\n",
        "            a[participant, video, 8] = int(raw[\"DREAMER\"][0, 0][\"Data\"]\n",
        "                                           [0, participant][\"ScoreDominance\"]\n",
        "                                           [0, 0][video, 0])\n",
        "    b = pd.DataFrame(a.reshape((23*18, a.shape[2])),\n",
        "                     columns=[\"age\", \"gender\", \"participant\",\n",
        "                              \"video\", \"video_name\", \"target_emotion\",\n",
        "                              \"valence\", \"arousal\", \"dominance\"])\n",
        "    return b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eb-QdQ4UIE3-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "7f6d0204-b38a-40cf-ffb4-18113d68727d"
      },
      "source": [
        "def_EEG3 = feat_extract_EEG(raw)\n",
        "#pd.def_EEG3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Electrode1_1  Electrode1_2  ...  Electrode14_7679  Electrode14_7680\n",
            "0     4376.923077   4380.512821  ...       4206.666667       4133.333333\n",
            "1     4396.923077   4394.358974  ...       4180.000000       4191.794872\n",
            "2     4387.692308   4382.051282  ...       4007.179487       3944.615385\n",
            "3     4396.923077   4401.538462  ...       4188.205128       4184.615385\n",
            "4     4398.461538   4395.897436  ...       4140.000000       4140.000000\n",
            "..            ...           ...  ...               ...               ...\n",
            "409   4356.410256   4360.512821  ...       4201.538462       4208.205128\n",
            "410   4381.538462   4377.435897  ...       4193.333333       4214.358974\n",
            "411   4355.384615   4358.974359  ...       4181.025641       4186.666667\n",
            "412   4381.538462   4382.051282  ...       4184.102564       4180.512821\n",
            "413   4397.948718   4395.384615  ...       4142.051282       4153.846154\n",
            "\n",
            "[414 rows x 107520 columns]\n",
            "     Electrode1_1  Electrode1_2  ...  Electrode14_7679  Electrode14_7680\n",
            "0        0.711454      0.816407  ...          0.296585          0.276508\n",
            "1        0.720999      0.824642  ...          0.290441          0.289939\n",
            "2        0.716593      0.817322  ...          0.250620          0.233153\n",
            "3        0.720999      0.828911  ...          0.292331          0.288289\n",
            "4        0.721733      0.825557  ...          0.281224          0.278040\n",
            "..            ...           ...  ...               ...               ...\n",
            "409      0.701664      0.804514  ...          0.295404          0.293709\n",
            "410      0.713656      0.814578  ...          0.293513          0.295123\n",
            "411      0.701175      0.803599  ...          0.290677          0.288761\n",
            "412      0.713656      0.817322  ...          0.291386          0.287347\n",
            "413      0.721488      0.825252  ...          0.281697          0.281221\n",
            "\n",
            "[414 rows x 107520 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHjGGyUDG-Hb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "outputId": "63f582ad-69d0-4d85-9760-92efb331c7c0"
      },
      "source": [
        "#Enter desired electrode\n",
        "df_features = def_EEG3\n",
        "#print(df_features)\n",
        "#print(df_participant_affective)\n",
        "df_participant_affective = participant_affective(raw)\n",
        "\n",
        "# not really clear to me why I have to do this because I thought these were already integers\n",
        "df_participant_affective[\"valence\"] = (df_participant_affective\n",
        "                                       [\"valence\"].astype(int))\n",
        "df_participant_affective[\"arousal\"] = (df_participant_affective\n",
        "                                       [\"arousal\"].astype(int))\n",
        "df_participant_affective[\"dominance\"] = (df_participant_affective\n",
        "                                         [\"dominance\"].astype(int))\n",
        "df = pd.concat([df_features, df_participant_affective], axis=1)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Electrode1_1</th>\n",
              "      <th>Electrode1_2</th>\n",
              "      <th>Electrode1_3</th>\n",
              "      <th>Electrode1_4</th>\n",
              "      <th>Electrode1_5</th>\n",
              "      <th>Electrode1_6</th>\n",
              "      <th>Electrode1_7</th>\n",
              "      <th>Electrode1_8</th>\n",
              "      <th>Electrode1_9</th>\n",
              "      <th>Electrode1_10</th>\n",
              "      <th>Electrode1_11</th>\n",
              "      <th>Electrode1_12</th>\n",
              "      <th>Electrode1_13</th>\n",
              "      <th>Electrode1_14</th>\n",
              "      <th>Electrode1_15</th>\n",
              "      <th>Electrode1_16</th>\n",
              "      <th>Electrode1_17</th>\n",
              "      <th>Electrode1_18</th>\n",
              "      <th>Electrode1_19</th>\n",
              "      <th>Electrode1_20</th>\n",
              "      <th>Electrode1_21</th>\n",
              "      <th>Electrode1_22</th>\n",
              "      <th>Electrode1_23</th>\n",
              "      <th>Electrode1_24</th>\n",
              "      <th>Electrode1_25</th>\n",
              "      <th>Electrode1_26</th>\n",
              "      <th>Electrode1_27</th>\n",
              "      <th>Electrode1_28</th>\n",
              "      <th>Electrode1_29</th>\n",
              "      <th>Electrode1_30</th>\n",
              "      <th>Electrode1_31</th>\n",
              "      <th>Electrode1_32</th>\n",
              "      <th>Electrode1_33</th>\n",
              "      <th>Electrode1_34</th>\n",
              "      <th>Electrode1_35</th>\n",
              "      <th>Electrode1_36</th>\n",
              "      <th>Electrode1_37</th>\n",
              "      <th>Electrode1_38</th>\n",
              "      <th>Electrode1_39</th>\n",
              "      <th>Electrode1_40</th>\n",
              "      <th>...</th>\n",
              "      <th>Electrode14_7650</th>\n",
              "      <th>Electrode14_7651</th>\n",
              "      <th>Electrode14_7652</th>\n",
              "      <th>Electrode14_7653</th>\n",
              "      <th>Electrode14_7654</th>\n",
              "      <th>Electrode14_7655</th>\n",
              "      <th>Electrode14_7656</th>\n",
              "      <th>Electrode14_7657</th>\n",
              "      <th>Electrode14_7658</th>\n",
              "      <th>Electrode14_7659</th>\n",
              "      <th>Electrode14_7660</th>\n",
              "      <th>Electrode14_7661</th>\n",
              "      <th>Electrode14_7662</th>\n",
              "      <th>Electrode14_7663</th>\n",
              "      <th>Electrode14_7664</th>\n",
              "      <th>Electrode14_7665</th>\n",
              "      <th>Electrode14_7666</th>\n",
              "      <th>Electrode14_7667</th>\n",
              "      <th>Electrode14_7668</th>\n",
              "      <th>Electrode14_7669</th>\n",
              "      <th>Electrode14_7670</th>\n",
              "      <th>Electrode14_7671</th>\n",
              "      <th>Electrode14_7672</th>\n",
              "      <th>Electrode14_7673</th>\n",
              "      <th>Electrode14_7674</th>\n",
              "      <th>Electrode14_7675</th>\n",
              "      <th>Electrode14_7676</th>\n",
              "      <th>Electrode14_7677</th>\n",
              "      <th>Electrode14_7678</th>\n",
              "      <th>Electrode14_7679</th>\n",
              "      <th>Electrode14_7680</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>participant</th>\n",
              "      <th>video</th>\n",
              "      <th>video_name</th>\n",
              "      <th>target_emotion</th>\n",
              "      <th>valence</th>\n",
              "      <th>arousal</th>\n",
              "      <th>dominance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.711454</td>\n",
              "      <td>0.816407</td>\n",
              "      <td>0.697264</td>\n",
              "      <td>0.623580</td>\n",
              "      <td>0.540883</td>\n",
              "      <td>0.697167</td>\n",
              "      <td>0.723525</td>\n",
              "      <td>0.664447</td>\n",
              "      <td>0.619359</td>\n",
              "      <td>0.600343</td>\n",
              "      <td>0.795455</td>\n",
              "      <td>0.692970</td>\n",
              "      <td>0.752745</td>\n",
              "      <td>0.748237</td>\n",
              "      <td>0.721244</td>\n",
              "      <td>0.812942</td>\n",
              "      <td>0.750268</td>\n",
              "      <td>0.713971</td>\n",
              "      <td>0.738795</td>\n",
              "      <td>0.846925</td>\n",
              "      <td>0.864148</td>\n",
              "      <td>0.750259</td>\n",
              "      <td>0.589057</td>\n",
              "      <td>0.649112</td>\n",
              "      <td>0.851468</td>\n",
              "      <td>0.727535</td>\n",
              "      <td>0.667166</td>\n",
              "      <td>0.513998</td>\n",
              "      <td>0.662799</td>\n",
              "      <td>0.776796</td>\n",
              "      <td>0.568155</td>\n",
              "      <td>0.500076</td>\n",
              "      <td>0.530692</td>\n",
              "      <td>0.573115</td>\n",
              "      <td>0.552580</td>\n",
              "      <td>0.448053</td>\n",
              "      <td>0.403018</td>\n",
              "      <td>0.367629</td>\n",
              "      <td>0.519017</td>\n",
              "      <td>0.452125</td>\n",
              "      <td>...</td>\n",
              "      <td>0.600570</td>\n",
              "      <td>0.535027</td>\n",
              "      <td>0.482174</td>\n",
              "      <td>0.444218</td>\n",
              "      <td>0.429233</td>\n",
              "      <td>0.417938</td>\n",
              "      <td>0.396732</td>\n",
              "      <td>0.375510</td>\n",
              "      <td>0.377816</td>\n",
              "      <td>0.389163</td>\n",
              "      <td>0.370040</td>\n",
              "      <td>0.328767</td>\n",
              "      <td>0.323363</td>\n",
              "      <td>0.343300</td>\n",
              "      <td>0.331148</td>\n",
              "      <td>0.334926</td>\n",
              "      <td>0.332230</td>\n",
              "      <td>0.325925</td>\n",
              "      <td>0.329387</td>\n",
              "      <td>0.333160</td>\n",
              "      <td>0.327799</td>\n",
              "      <td>0.319943</td>\n",
              "      <td>0.317603</td>\n",
              "      <td>0.326645</td>\n",
              "      <td>0.328819</td>\n",
              "      <td>0.315980</td>\n",
              "      <td>0.302303</td>\n",
              "      <td>0.298552</td>\n",
              "      <td>0.304833</td>\n",
              "      <td>0.296585</td>\n",
              "      <td>0.276508</td>\n",
              "      <td>22</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Searching for Bobby Fischer</td>\n",
              "      <td>calmness</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.720999</td>\n",
              "      <td>0.824642</td>\n",
              "      <td>0.701456</td>\n",
              "      <td>0.629354</td>\n",
              "      <td>0.548922</td>\n",
              "      <td>0.707850</td>\n",
              "      <td>0.731817</td>\n",
              "      <td>0.670715</td>\n",
              "      <td>0.626261</td>\n",
              "      <td>0.608348</td>\n",
              "      <td>0.805158</td>\n",
              "      <td>0.699980</td>\n",
              "      <td>0.760697</td>\n",
              "      <td>0.756772</td>\n",
              "      <td>0.729119</td>\n",
              "      <td>0.823306</td>\n",
              "      <td>0.760343</td>\n",
              "      <td>0.721423</td>\n",
              "      <td>0.744670</td>\n",
              "      <td>0.850936</td>\n",
              "      <td>0.867150</td>\n",
              "      <td>0.756477</td>\n",
              "      <td>0.596873</td>\n",
              "      <td>0.656294</td>\n",
              "      <td>0.853543</td>\n",
              "      <td>0.726749</td>\n",
              "      <td>0.671016</td>\n",
              "      <td>0.519910</td>\n",
              "      <td>0.669217</td>\n",
              "      <td>0.780624</td>\n",
              "      <td>0.573094</td>\n",
              "      <td>0.505563</td>\n",
              "      <td>0.536576</td>\n",
              "      <td>0.578516</td>\n",
              "      <td>0.559275</td>\n",
              "      <td>0.457948</td>\n",
              "      <td>0.411667</td>\n",
              "      <td>0.375157</td>\n",
              "      <td>0.526581</td>\n",
              "      <td>0.463335</td>\n",
              "      <td>...</td>\n",
              "      <td>0.591586</td>\n",
              "      <td>0.538233</td>\n",
              "      <td>0.513864</td>\n",
              "      <td>0.485009</td>\n",
              "      <td>0.447577</td>\n",
              "      <td>0.438965</td>\n",
              "      <td>0.443438</td>\n",
              "      <td>0.438332</td>\n",
              "      <td>0.420980</td>\n",
              "      <td>0.392611</td>\n",
              "      <td>0.379576</td>\n",
              "      <td>0.363888</td>\n",
              "      <td>0.354684</td>\n",
              "      <td>0.351318</td>\n",
              "      <td>0.320224</td>\n",
              "      <td>0.334789</td>\n",
              "      <td>0.346021</td>\n",
              "      <td>0.342594</td>\n",
              "      <td>0.321363</td>\n",
              "      <td>0.313929</td>\n",
              "      <td>0.320664</td>\n",
              "      <td>0.326143</td>\n",
              "      <td>0.317346</td>\n",
              "      <td>0.304665</td>\n",
              "      <td>0.306543</td>\n",
              "      <td>0.308382</td>\n",
              "      <td>0.306202</td>\n",
              "      <td>0.300586</td>\n",
              "      <td>0.291296</td>\n",
              "      <td>0.290441</td>\n",
              "      <td>0.289939</td>\n",
              "      <td>22</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>D.O.A.</td>\n",
              "      <td>surprise</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.716593</td>\n",
              "      <td>0.817322</td>\n",
              "      <td>0.703663</td>\n",
              "      <td>0.635128</td>\n",
              "      <td>0.549264</td>\n",
              "      <td>0.698792</td>\n",
              "      <td>0.725657</td>\n",
              "      <td>0.675416</td>\n",
              "      <td>0.631039</td>\n",
              "      <td>0.604536</td>\n",
              "      <td>0.796221</td>\n",
              "      <td>0.700781</td>\n",
              "      <td>0.766376</td>\n",
              "      <td>0.756215</td>\n",
              "      <td>0.719793</td>\n",
              "      <td>0.815470</td>\n",
              "      <td>0.762701</td>\n",
              "      <td>0.724979</td>\n",
              "      <td>0.743327</td>\n",
              "      <td>0.846702</td>\n",
              "      <td>0.868651</td>\n",
              "      <td>0.761658</td>\n",
              "      <td>0.599035</td>\n",
              "      <td>0.653700</td>\n",
              "      <td>0.849689</td>\n",
              "      <td>0.731988</td>\n",
              "      <td>0.678717</td>\n",
              "      <td>0.520605</td>\n",
              "      <td>0.660331</td>\n",
              "      <td>0.777091</td>\n",
              "      <td>0.579415</td>\n",
              "      <td>0.509069</td>\n",
              "      <td>0.532065</td>\n",
              "      <td>0.572715</td>\n",
              "      <td>0.560654</td>\n",
              "      <td>0.462680</td>\n",
              "      <td>0.410195</td>\n",
              "      <td>0.368465</td>\n",
              "      <td>0.522799</td>\n",
              "      <td>0.465904</td>\n",
              "      <td>...</td>\n",
              "      <td>0.573181</td>\n",
              "      <td>0.501603</td>\n",
              "      <td>0.443002</td>\n",
              "      <td>0.425658</td>\n",
              "      <td>0.417648</td>\n",
              "      <td>0.405843</td>\n",
              "      <td>0.394956</td>\n",
              "      <td>0.385626</td>\n",
              "      <td>0.387274</td>\n",
              "      <td>0.378654</td>\n",
              "      <td>0.362965</td>\n",
              "      <td>0.343049</td>\n",
              "      <td>0.343962</td>\n",
              "      <td>0.363006</td>\n",
              "      <td>0.334972</td>\n",
              "      <td>0.310222</td>\n",
              "      <td>0.308233</td>\n",
              "      <td>0.291096</td>\n",
              "      <td>0.279795</td>\n",
              "      <td>0.281575</td>\n",
              "      <td>0.284084</td>\n",
              "      <td>0.274219</td>\n",
              "      <td>0.263598</td>\n",
              "      <td>0.266709</td>\n",
              "      <td>0.265663</td>\n",
              "      <td>0.255200</td>\n",
              "      <td>0.245400</td>\n",
              "      <td>0.243748</td>\n",
              "      <td>0.253295</td>\n",
              "      <td>0.250620</td>\n",
              "      <td>0.233153</td>\n",
              "      <td>22</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>The Hangover</td>\n",
              "      <td>amusement</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.720999</td>\n",
              "      <td>0.828911</td>\n",
              "      <td>0.705207</td>\n",
              "      <td>0.629726</td>\n",
              "      <td>0.547212</td>\n",
              "      <td>0.706456</td>\n",
              "      <td>0.733239</td>\n",
              "      <td>0.672870</td>\n",
              "      <td>0.626792</td>\n",
              "      <td>0.607395</td>\n",
              "      <td>0.805414</td>\n",
              "      <td>0.702183</td>\n",
              "      <td>0.761833</td>\n",
              "      <td>0.755288</td>\n",
              "      <td>0.728290</td>\n",
              "      <td>0.823812</td>\n",
              "      <td>0.758414</td>\n",
              "      <td>0.718713</td>\n",
              "      <td>0.743831</td>\n",
              "      <td>0.853832</td>\n",
              "      <td>0.871904</td>\n",
              "      <td>0.756891</td>\n",
              "      <td>0.594379</td>\n",
              "      <td>0.655097</td>\n",
              "      <td>0.858879</td>\n",
              "      <td>0.730417</td>\n",
              "      <td>0.671016</td>\n",
              "      <td>0.519388</td>\n",
              "      <td>0.668230</td>\n",
              "      <td>0.783274</td>\n",
              "      <td>0.576650</td>\n",
              "      <td>0.507087</td>\n",
              "      <td>0.536772</td>\n",
              "      <td>0.580116</td>\n",
              "      <td>0.561245</td>\n",
              "      <td>0.457088</td>\n",
              "      <td>0.410379</td>\n",
              "      <td>0.377457</td>\n",
              "      <td>0.529523</td>\n",
              "      <td>0.462868</td>\n",
              "      <td>...</td>\n",
              "      <td>0.593996</td>\n",
              "      <td>0.523123</td>\n",
              "      <td>0.511884</td>\n",
              "      <td>0.506221</td>\n",
              "      <td>0.471713</td>\n",
              "      <td>0.443245</td>\n",
              "      <td>0.439709</td>\n",
              "      <td>0.452884</td>\n",
              "      <td>0.451591</td>\n",
              "      <td>0.416420</td>\n",
              "      <td>0.383420</td>\n",
              "      <td>0.371029</td>\n",
              "      <td>0.385440</td>\n",
              "      <td>0.388557</td>\n",
              "      <td>0.342209</td>\n",
              "      <td>0.333697</td>\n",
              "      <td>0.345470</td>\n",
              "      <td>0.349370</td>\n",
              "      <td>0.325835</td>\n",
              "      <td>0.301585</td>\n",
              "      <td>0.305487</td>\n",
              "      <td>0.314131</td>\n",
              "      <td>0.308602</td>\n",
              "      <td>0.296613</td>\n",
              "      <td>0.289963</td>\n",
              "      <td>0.296550</td>\n",
              "      <td>0.302059</td>\n",
              "      <td>0.316022</td>\n",
              "      <td>0.311127</td>\n",
              "      <td>0.292331</td>\n",
              "      <td>0.288289</td>\n",
              "      <td>22</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>The Ring</td>\n",
              "      <td>fear</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.721733</td>\n",
              "      <td>0.825557</td>\n",
              "      <td>0.699912</td>\n",
              "      <td>0.627119</td>\n",
              "      <td>0.547725</td>\n",
              "      <td>0.706688</td>\n",
              "      <td>0.728500</td>\n",
              "      <td>0.667581</td>\n",
              "      <td>0.624491</td>\n",
              "      <td>0.606442</td>\n",
              "      <td>0.802605</td>\n",
              "      <td>0.698177</td>\n",
              "      <td>0.758425</td>\n",
              "      <td>0.753618</td>\n",
              "      <td>0.727254</td>\n",
              "      <td>0.822548</td>\n",
              "      <td>0.757985</td>\n",
              "      <td>0.718713</td>\n",
              "      <td>0.743999</td>\n",
              "      <td>0.852496</td>\n",
              "      <td>0.866900</td>\n",
              "      <td>0.755440</td>\n",
              "      <td>0.596707</td>\n",
              "      <td>0.655695</td>\n",
              "      <td>0.852060</td>\n",
              "      <td>0.726487</td>\n",
              "      <td>0.670802</td>\n",
              "      <td>0.519040</td>\n",
              "      <td>0.668724</td>\n",
              "      <td>0.781508</td>\n",
              "      <td>0.571711</td>\n",
              "      <td>0.503125</td>\n",
              "      <td>0.534419</td>\n",
              "      <td>0.578916</td>\n",
              "      <td>0.560063</td>\n",
              "      <td>0.455797</td>\n",
              "      <td>0.409091</td>\n",
              "      <td>0.375366</td>\n",
              "      <td>0.527842</td>\n",
              "      <td>0.460532</td>\n",
              "      <td>...</td>\n",
              "      <td>0.565951</td>\n",
              "      <td>0.575092</td>\n",
              "      <td>0.583847</td>\n",
              "      <td>0.519274</td>\n",
              "      <td>0.458197</td>\n",
              "      <td>0.465761</td>\n",
              "      <td>0.503463</td>\n",
              "      <td>0.488199</td>\n",
              "      <td>0.434222</td>\n",
              "      <td>0.401970</td>\n",
              "      <td>0.399569</td>\n",
              "      <td>0.399155</td>\n",
              "      <td>0.375705</td>\n",
              "      <td>0.343164</td>\n",
              "      <td>0.323228</td>\n",
              "      <td>0.350348</td>\n",
              "      <td>0.355537</td>\n",
              "      <td>0.325518</td>\n",
              "      <td>0.296369</td>\n",
              "      <td>0.308732</td>\n",
              "      <td>0.331301</td>\n",
              "      <td>0.325239</td>\n",
              "      <td>0.302044</td>\n",
              "      <td>0.340447</td>\n",
              "      <td>0.305278</td>\n",
              "      <td>0.279362</td>\n",
              "      <td>0.297673</td>\n",
              "      <td>0.317099</td>\n",
              "      <td>0.305071</td>\n",
              "      <td>0.281224</td>\n",
              "      <td>0.278040</td>\n",
              "      <td>22</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>300</td>\n",
              "      <td>excitement</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>409</th>\n",
              "      <td>0.701664</td>\n",
              "      <td>0.804514</td>\n",
              "      <td>0.695057</td>\n",
              "      <td>0.626187</td>\n",
              "      <td>0.541738</td>\n",
              "      <td>0.692754</td>\n",
              "      <td>0.717839</td>\n",
              "      <td>0.663859</td>\n",
              "      <td>0.619890</td>\n",
              "      <td>0.596150</td>\n",
              "      <td>0.787794</td>\n",
              "      <td>0.690767</td>\n",
              "      <td>0.754638</td>\n",
              "      <td>0.750278</td>\n",
              "      <td>0.719378</td>\n",
              "      <td>0.811426</td>\n",
              "      <td>0.752840</td>\n",
              "      <td>0.716003</td>\n",
              "      <td>0.736612</td>\n",
              "      <td>0.839349</td>\n",
              "      <td>0.858144</td>\n",
              "      <td>0.750466</td>\n",
              "      <td>0.589057</td>\n",
              "      <td>0.643926</td>\n",
              "      <td>0.837533</td>\n",
              "      <td>0.717055</td>\n",
              "      <td>0.662888</td>\n",
              "      <td>0.509129</td>\n",
              "      <td>0.651691</td>\n",
              "      <td>0.770024</td>\n",
              "      <td>0.570130</td>\n",
              "      <td>0.500838</td>\n",
              "      <td>0.526966</td>\n",
              "      <td>0.569714</td>\n",
              "      <td>0.553761</td>\n",
              "      <td>0.453431</td>\n",
              "      <td>0.405226</td>\n",
              "      <td>0.368047</td>\n",
              "      <td>0.523429</td>\n",
              "      <td>0.460065</td>\n",
              "      <td>...</td>\n",
              "      <td>0.613278</td>\n",
              "      <td>0.557463</td>\n",
              "      <td>0.524648</td>\n",
              "      <td>0.501938</td>\n",
              "      <td>0.477891</td>\n",
              "      <td>0.463900</td>\n",
              "      <td>0.455869</td>\n",
              "      <td>0.442059</td>\n",
              "      <td>0.430095</td>\n",
              "      <td>0.411002</td>\n",
              "      <td>0.383420</td>\n",
              "      <td>0.356019</td>\n",
              "      <td>0.354684</td>\n",
              "      <td>0.364637</td>\n",
              "      <td>0.337567</td>\n",
              "      <td>0.335199</td>\n",
              "      <td>0.338574</td>\n",
              "      <td>0.334598</td>\n",
              "      <td>0.325309</td>\n",
              "      <td>0.321726</td>\n",
              "      <td>0.319237</td>\n",
              "      <td>0.315810</td>\n",
              "      <td>0.316446</td>\n",
              "      <td>0.316805</td>\n",
              "      <td>0.312239</td>\n",
              "      <td>0.306389</td>\n",
              "      <td>0.302668</td>\n",
              "      <td>0.300706</td>\n",
              "      <td>0.298777</td>\n",
              "      <td>0.295404</td>\n",
              "      <td>0.293709</td>\n",
              "      <td>25</td>\n",
              "      <td>male</td>\n",
              "      <td>23</td>\n",
              "      <td>14</td>\n",
              "      <td>Gentlemans Agreement</td>\n",
              "      <td>anger</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410</th>\n",
              "      <td>0.713656</td>\n",
              "      <td>0.814578</td>\n",
              "      <td>0.699912</td>\n",
              "      <td>0.629354</td>\n",
              "      <td>0.546699</td>\n",
              "      <td>0.703669</td>\n",
              "      <td>0.729922</td>\n",
              "      <td>0.672282</td>\n",
              "      <td>0.627500</td>\n",
              "      <td>0.605298</td>\n",
              "      <td>0.799540</td>\n",
              "      <td>0.701782</td>\n",
              "      <td>0.767134</td>\n",
              "      <td>0.758442</td>\n",
              "      <td>0.722280</td>\n",
              "      <td>0.813195</td>\n",
              "      <td>0.756056</td>\n",
              "      <td>0.719221</td>\n",
              "      <td>0.740473</td>\n",
              "      <td>0.847148</td>\n",
              "      <td>0.868651</td>\n",
              "      <td>0.757927</td>\n",
              "      <td>0.595210</td>\n",
              "      <td>0.651307</td>\n",
              "      <td>0.847613</td>\n",
              "      <td>0.725701</td>\n",
              "      <td>0.671016</td>\n",
              "      <td>0.516954</td>\n",
              "      <td>0.661565</td>\n",
              "      <td>0.773852</td>\n",
              "      <td>0.569340</td>\n",
              "      <td>0.502515</td>\n",
              "      <td>0.530692</td>\n",
              "      <td>0.571714</td>\n",
              "      <td>0.555337</td>\n",
              "      <td>0.454937</td>\n",
              "      <td>0.406331</td>\n",
              "      <td>0.367629</td>\n",
              "      <td>0.523219</td>\n",
              "      <td>0.466371</td>\n",
              "      <td>...</td>\n",
              "      <td>0.596626</td>\n",
              "      <td>0.543040</td>\n",
              "      <td>0.511224</td>\n",
              "      <td>0.485213</td>\n",
              "      <td>0.459162</td>\n",
              "      <td>0.444362</td>\n",
              "      <td>0.436157</td>\n",
              "      <td>0.424135</td>\n",
              "      <td>0.415993</td>\n",
              "      <td>0.399343</td>\n",
              "      <td>0.372655</td>\n",
              "      <td>0.352521</td>\n",
              "      <td>0.360045</td>\n",
              "      <td>0.369802</td>\n",
              "      <td>0.336884</td>\n",
              "      <td>0.332742</td>\n",
              "      <td>0.339126</td>\n",
              "      <td>0.336360</td>\n",
              "      <td>0.325178</td>\n",
              "      <td>0.320296</td>\n",
              "      <td>0.318070</td>\n",
              "      <td>0.312710</td>\n",
              "      <td>0.308859</td>\n",
              "      <td>0.310032</td>\n",
              "      <td>0.305911</td>\n",
              "      <td>0.300037</td>\n",
              "      <td>0.294261</td>\n",
              "      <td>0.291014</td>\n",
              "      <td>0.291177</td>\n",
              "      <td>0.293513</td>\n",
              "      <td>0.295123</td>\n",
              "      <td>25</td>\n",
              "      <td>male</td>\n",
              "      <td>23</td>\n",
              "      <td>15</td>\n",
              "      <td>Psycho</td>\n",
              "      <td>fear</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>0.701175</td>\n",
              "      <td>0.803599</td>\n",
              "      <td>0.691306</td>\n",
              "      <td>0.617620</td>\n",
              "      <td>0.532159</td>\n",
              "      <td>0.683697</td>\n",
              "      <td>0.711680</td>\n",
              "      <td>0.657003</td>\n",
              "      <td>0.613697</td>\n",
              "      <td>0.591386</td>\n",
              "      <td>0.779877</td>\n",
              "      <td>0.684358</td>\n",
              "      <td>0.749148</td>\n",
              "      <td>0.743414</td>\n",
              "      <td>0.711503</td>\n",
              "      <td>0.803337</td>\n",
              "      <td>0.744480</td>\n",
              "      <td>0.707028</td>\n",
              "      <td>0.726372</td>\n",
              "      <td>0.826872</td>\n",
              "      <td>0.849637</td>\n",
              "      <td>0.744249</td>\n",
              "      <td>0.581573</td>\n",
              "      <td>0.634750</td>\n",
              "      <td>0.827750</td>\n",
              "      <td>0.709196</td>\n",
              "      <td>0.655615</td>\n",
              "      <td>0.503391</td>\n",
              "      <td>0.641076</td>\n",
              "      <td>0.752356</td>\n",
              "      <td>0.558080</td>\n",
              "      <td>0.491846</td>\n",
              "      <td>0.514218</td>\n",
              "      <td>0.558712</td>\n",
              "      <td>0.546869</td>\n",
              "      <td>0.442031</td>\n",
              "      <td>0.392713</td>\n",
              "      <td>0.355709</td>\n",
              "      <td>0.512713</td>\n",
              "      <td>0.449323</td>\n",
              "      <td>...</td>\n",
              "      <td>0.589395</td>\n",
              "      <td>0.537317</td>\n",
              "      <td>0.504401</td>\n",
              "      <td>0.480318</td>\n",
              "      <td>0.455107</td>\n",
              "      <td>0.440640</td>\n",
              "      <td>0.434559</td>\n",
              "      <td>0.424312</td>\n",
              "      <td>0.415305</td>\n",
              "      <td>0.397865</td>\n",
              "      <td>0.374500</td>\n",
              "      <td>0.351938</td>\n",
              "      <td>0.350028</td>\n",
              "      <td>0.356890</td>\n",
              "      <td>0.329237</td>\n",
              "      <td>0.327010</td>\n",
              "      <td>0.329886</td>\n",
              "      <td>0.326331</td>\n",
              "      <td>0.317022</td>\n",
              "      <td>0.312110</td>\n",
              "      <td>0.310157</td>\n",
              "      <td>0.309481</td>\n",
              "      <td>0.312588</td>\n",
              "      <td>0.308882</td>\n",
              "      <td>0.305025</td>\n",
              "      <td>0.300660</td>\n",
              "      <td>0.297185</td>\n",
              "      <td>0.293048</td>\n",
              "      <td>0.291177</td>\n",
              "      <td>0.290677</td>\n",
              "      <td>0.288761</td>\n",
              "      <td>25</td>\n",
              "      <td>male</td>\n",
              "      <td>23</td>\n",
              "      <td>16</td>\n",
              "      <td>The Bourne Identitiy</td>\n",
              "      <td>excitement</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>412</th>\n",
              "      <td>0.713656</td>\n",
              "      <td>0.817322</td>\n",
              "      <td>0.699912</td>\n",
              "      <td>0.626560</td>\n",
              "      <td>0.542251</td>\n",
              "      <td>0.694380</td>\n",
              "      <td>0.719972</td>\n",
              "      <td>0.668168</td>\n",
              "      <td>0.624137</td>\n",
              "      <td>0.599200</td>\n",
              "      <td>0.792901</td>\n",
              "      <td>0.697977</td>\n",
              "      <td>0.760129</td>\n",
              "      <td>0.751948</td>\n",
              "      <td>0.721036</td>\n",
              "      <td>0.814206</td>\n",
              "      <td>0.756056</td>\n",
              "      <td>0.718544</td>\n",
              "      <td>0.738459</td>\n",
              "      <td>0.842914</td>\n",
              "      <td>0.865149</td>\n",
              "      <td>0.755855</td>\n",
              "      <td>0.590720</td>\n",
              "      <td>0.642928</td>\n",
              "      <td>0.839609</td>\n",
              "      <td>0.725701</td>\n",
              "      <td>0.673155</td>\n",
              "      <td>0.517649</td>\n",
              "      <td>0.663787</td>\n",
              "      <td>0.789458</td>\n",
              "      <td>0.590873</td>\n",
              "      <td>0.520195</td>\n",
              "      <td>0.553050</td>\n",
              "      <td>0.601520</td>\n",
              "      <td>0.586254</td>\n",
              "      <td>0.482039</td>\n",
              "      <td>0.428414</td>\n",
              "      <td>0.393977</td>\n",
              "      <td>0.542551</td>\n",
              "      <td>0.476413</td>\n",
              "      <td>...</td>\n",
              "      <td>0.591367</td>\n",
              "      <td>0.537088</td>\n",
              "      <td>0.507482</td>\n",
              "      <td>0.487865</td>\n",
              "      <td>0.466113</td>\n",
              "      <td>0.451805</td>\n",
              "      <td>0.443083</td>\n",
              "      <td>0.430524</td>\n",
              "      <td>0.421152</td>\n",
              "      <td>0.402299</td>\n",
              "      <td>0.374500</td>\n",
              "      <td>0.350189</td>\n",
              "      <td>0.349746</td>\n",
              "      <td>0.356890</td>\n",
              "      <td>0.328554</td>\n",
              "      <td>0.326327</td>\n",
              "      <td>0.329196</td>\n",
              "      <td>0.327551</td>\n",
              "      <td>0.320705</td>\n",
              "      <td>0.316008</td>\n",
              "      <td>0.314308</td>\n",
              "      <td>0.312710</td>\n",
              "      <td>0.311045</td>\n",
              "      <td>0.309649</td>\n",
              "      <td>0.306417</td>\n",
              "      <td>0.301034</td>\n",
              "      <td>0.295845</td>\n",
              "      <td>0.300467</td>\n",
              "      <td>0.295452</td>\n",
              "      <td>0.291386</td>\n",
              "      <td>0.287347</td>\n",
              "      <td>25</td>\n",
              "      <td>male</td>\n",
              "      <td>23</td>\n",
              "      <td>17</td>\n",
              "      <td>The Shawshank Redemption</td>\n",
              "      <td>sadness</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>0.721488</td>\n",
              "      <td>0.825252</td>\n",
              "      <td>0.707635</td>\n",
              "      <td>0.636245</td>\n",
              "      <td>0.550120</td>\n",
              "      <td>0.704598</td>\n",
              "      <td>0.733475</td>\n",
              "      <td>0.677375</td>\n",
              "      <td>0.631216</td>\n",
              "      <td>0.609682</td>\n",
              "      <td>0.807967</td>\n",
              "      <td>0.706189</td>\n",
              "      <td>0.766187</td>\n",
              "      <td>0.758071</td>\n",
              "      <td>0.727876</td>\n",
              "      <td>0.821537</td>\n",
              "      <td>0.760557</td>\n",
              "      <td>0.722947</td>\n",
              "      <td>0.745342</td>\n",
              "      <td>0.852273</td>\n",
              "      <td>0.872404</td>\n",
              "      <td>0.760415</td>\n",
              "      <td>0.596707</td>\n",
              "      <td>0.654299</td>\n",
              "      <td>0.856508</td>\n",
              "      <td>0.738014</td>\n",
              "      <td>0.680856</td>\n",
              "      <td>0.522344</td>\n",
              "      <td>0.666749</td>\n",
              "      <td>0.785041</td>\n",
              "      <td>0.582379</td>\n",
              "      <td>0.511050</td>\n",
              "      <td>0.538145</td>\n",
              "      <td>0.581716</td>\n",
              "      <td>0.568728</td>\n",
              "      <td>0.468488</td>\n",
              "      <td>0.415532</td>\n",
              "      <td>0.376830</td>\n",
              "      <td>0.531834</td>\n",
              "      <td>0.475012</td>\n",
              "      <td>...</td>\n",
              "      <td>0.577564</td>\n",
              "      <td>0.525641</td>\n",
              "      <td>0.495379</td>\n",
              "      <td>0.469101</td>\n",
              "      <td>0.442170</td>\n",
              "      <td>0.430033</td>\n",
              "      <td>0.429231</td>\n",
              "      <td>0.421118</td>\n",
              "      <td>0.409630</td>\n",
              "      <td>0.390969</td>\n",
              "      <td>0.369271</td>\n",
              "      <td>0.348003</td>\n",
              "      <td>0.346642</td>\n",
              "      <td>0.352949</td>\n",
              "      <td>0.323638</td>\n",
              "      <td>0.321005</td>\n",
              "      <td>0.325197</td>\n",
              "      <td>0.322672</td>\n",
              "      <td>0.313076</td>\n",
              "      <td>0.307952</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.307931</td>\n",
              "      <td>0.308859</td>\n",
              "      <td>0.308115</td>\n",
              "      <td>0.305404</td>\n",
              "      <td>0.301283</td>\n",
              "      <td>0.294627</td>\n",
              "      <td>0.287543</td>\n",
              "      <td>0.283102</td>\n",
              "      <td>0.281697</td>\n",
              "      <td>0.281221</td>\n",
              "      <td>25</td>\n",
              "      <td>male</td>\n",
              "      <td>23</td>\n",
              "      <td>18</td>\n",
              "      <td>The Departed</td>\n",
              "      <td>surprise</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>414 rows × 107529 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Electrode1_1  Electrode1_2  Electrode1_3  ...  valence  arousal  dominance\n",
              "0        0.711454      0.816407      0.697264  ...        4        3          2\n",
              "1        0.720999      0.824642      0.701456  ...        3        3          1\n",
              "2        0.716593      0.817322      0.703663  ...        5        4          4\n",
              "3        0.720999      0.828911      0.705207  ...        4        3          2\n",
              "4        0.721733      0.825557      0.699912  ...        4        4          4\n",
              "..            ...           ...           ...  ...      ...      ...        ...\n",
              "409      0.701664      0.804514      0.695057  ...        2        2          2\n",
              "410      0.713656      0.814578      0.699912  ...        2        2          2\n",
              "411      0.701175      0.803599      0.691306  ...        3        3          2\n",
              "412      0.713656      0.817322      0.699912  ...        2        2          4\n",
              "413      0.721488      0.825252      0.707635  ...        2        4          2\n",
              "\n",
              "[414 rows x 107529 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSyb0Lej1IAR"
      },
      "source": [
        "data2 = df.loc[(df['target_emotion'] == 'anger') |\n",
        "                (df['target_emotion'] == 'fear') |\n",
        "                (df['target_emotion'] == 'calmness') |\n",
        "                (df['target_emotion'] == 'surprise') |\n",
        "                (df['target_emotion'] == 'excitement') |\n",
        "                (df['target_emotion'] == 'amusement') |\n",
        "                (df['target_emotion'] == 'happiness') |\n",
        "                (df['target_emotion'] == 'sadness') |\n",
        "                (df['target_emotion'] == 'disgust')].copy()\n",
        "\n",
        "d={'surprise': 0, 'excitement': 0, 'amusement': 0, 'happiness': 0, 'fear': 1, 'anger': 1, 'sadness':2, 'disgust':2 ,'calmness': 3}\n",
        "data2['class'] = data2.target_emotion.map(d)\n",
        "\n",
        "e={0: 0, 1: 0, 2: 0, 3: 1, 4: 1, 5: 1 }\n",
        "data2['valencehigh'] = data2.valence.map(e)\n",
        "\n",
        "f={0: 0, 1: 0, 2: 0, 3: 1, 4: 1, 5: 1 }\n",
        "data2['arousalhigh'] = data2.arousal.map(e)\n",
        "\n",
        "# add another column with title 'stress_bin' and give it value 0/1 depending on what emotion it elicits\n",
        "#data['stress_bin'] = data['target_emotion'].map({'anger': 1, 'fear': 1, 'calmness': 0})\n",
        "\n",
        "# save features, demographic, and emotion data as csv\n",
        "data2.to_csv('normalized.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3gNKfUdWbs5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc74ec43-866e-4563-d713-46f1be93261e"
      },
      "source": [
        "print(\"a\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAvsSOoz-FH5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "e594327d-281a-4a6f-ff61-988091ac3744"
      },
      "source": [
        "data2 = pd.read_csv(\"normalized.csv\")  \n",
        "data_2 = data2.head()\n",
        "data_2  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Electrode1_1</th>\n",
              "      <th>Electrode1_2</th>\n",
              "      <th>Electrode1_3</th>\n",
              "      <th>Electrode1_4</th>\n",
              "      <th>Electrode1_5</th>\n",
              "      <th>Electrode1_6</th>\n",
              "      <th>Electrode1_7</th>\n",
              "      <th>Electrode1_8</th>\n",
              "      <th>Electrode1_9</th>\n",
              "      <th>Electrode1_10</th>\n",
              "      <th>Electrode1_11</th>\n",
              "      <th>Electrode1_12</th>\n",
              "      <th>Electrode1_13</th>\n",
              "      <th>Electrode1_14</th>\n",
              "      <th>Electrode1_15</th>\n",
              "      <th>Electrode1_16</th>\n",
              "      <th>Electrode1_17</th>\n",
              "      <th>Electrode1_18</th>\n",
              "      <th>Electrode1_19</th>\n",
              "      <th>Electrode1_20</th>\n",
              "      <th>Electrode1_21</th>\n",
              "      <th>Electrode1_22</th>\n",
              "      <th>Electrode1_23</th>\n",
              "      <th>Electrode1_24</th>\n",
              "      <th>Electrode1_25</th>\n",
              "      <th>Electrode1_26</th>\n",
              "      <th>Electrode1_27</th>\n",
              "      <th>Electrode1_28</th>\n",
              "      <th>Electrode1_29</th>\n",
              "      <th>Electrode1_30</th>\n",
              "      <th>Electrode1_31</th>\n",
              "      <th>Electrode1_32</th>\n",
              "      <th>Electrode1_33</th>\n",
              "      <th>Electrode1_34</th>\n",
              "      <th>Electrode1_35</th>\n",
              "      <th>Electrode1_36</th>\n",
              "      <th>Electrode1_37</th>\n",
              "      <th>Electrode1_38</th>\n",
              "      <th>Electrode1_39</th>\n",
              "      <th>...</th>\n",
              "      <th>Electrode14_7653</th>\n",
              "      <th>Electrode14_7654</th>\n",
              "      <th>Electrode14_7655</th>\n",
              "      <th>Electrode14_7656</th>\n",
              "      <th>Electrode14_7657</th>\n",
              "      <th>Electrode14_7658</th>\n",
              "      <th>Electrode14_7659</th>\n",
              "      <th>Electrode14_7660</th>\n",
              "      <th>Electrode14_7661</th>\n",
              "      <th>Electrode14_7662</th>\n",
              "      <th>Electrode14_7663</th>\n",
              "      <th>Electrode14_7664</th>\n",
              "      <th>Electrode14_7665</th>\n",
              "      <th>Electrode14_7666</th>\n",
              "      <th>Electrode14_7667</th>\n",
              "      <th>Electrode14_7668</th>\n",
              "      <th>Electrode14_7669</th>\n",
              "      <th>Electrode14_7670</th>\n",
              "      <th>Electrode14_7671</th>\n",
              "      <th>Electrode14_7672</th>\n",
              "      <th>Electrode14_7673</th>\n",
              "      <th>Electrode14_7674</th>\n",
              "      <th>Electrode14_7675</th>\n",
              "      <th>Electrode14_7676</th>\n",
              "      <th>Electrode14_7677</th>\n",
              "      <th>Electrode14_7678</th>\n",
              "      <th>Electrode14_7679</th>\n",
              "      <th>Electrode14_7680</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>participant</th>\n",
              "      <th>video</th>\n",
              "      <th>video_name</th>\n",
              "      <th>target_emotion</th>\n",
              "      <th>valence</th>\n",
              "      <th>arousal</th>\n",
              "      <th>dominance</th>\n",
              "      <th>class</th>\n",
              "      <th>valencehigh</th>\n",
              "      <th>arousalhigh</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.711454</td>\n",
              "      <td>0.816407</td>\n",
              "      <td>0.697264</td>\n",
              "      <td>0.623580</td>\n",
              "      <td>0.540883</td>\n",
              "      <td>0.697167</td>\n",
              "      <td>0.723525</td>\n",
              "      <td>0.664447</td>\n",
              "      <td>0.619359</td>\n",
              "      <td>0.600343</td>\n",
              "      <td>0.795455</td>\n",
              "      <td>0.692970</td>\n",
              "      <td>0.752745</td>\n",
              "      <td>0.748237</td>\n",
              "      <td>0.721244</td>\n",
              "      <td>0.812942</td>\n",
              "      <td>0.750268</td>\n",
              "      <td>0.713971</td>\n",
              "      <td>0.738795</td>\n",
              "      <td>0.846925</td>\n",
              "      <td>0.864148</td>\n",
              "      <td>0.750259</td>\n",
              "      <td>0.589057</td>\n",
              "      <td>0.649112</td>\n",
              "      <td>0.851468</td>\n",
              "      <td>0.727535</td>\n",
              "      <td>0.667166</td>\n",
              "      <td>0.513998</td>\n",
              "      <td>0.662799</td>\n",
              "      <td>0.776796</td>\n",
              "      <td>0.568155</td>\n",
              "      <td>0.500076</td>\n",
              "      <td>0.530692</td>\n",
              "      <td>0.573115</td>\n",
              "      <td>0.552580</td>\n",
              "      <td>0.448053</td>\n",
              "      <td>0.403018</td>\n",
              "      <td>0.367629</td>\n",
              "      <td>0.519017</td>\n",
              "      <td>...</td>\n",
              "      <td>0.444218</td>\n",
              "      <td>0.429233</td>\n",
              "      <td>0.417938</td>\n",
              "      <td>0.396732</td>\n",
              "      <td>0.375510</td>\n",
              "      <td>0.377816</td>\n",
              "      <td>0.389163</td>\n",
              "      <td>0.370040</td>\n",
              "      <td>0.328767</td>\n",
              "      <td>0.323363</td>\n",
              "      <td>0.343300</td>\n",
              "      <td>0.331148</td>\n",
              "      <td>0.334926</td>\n",
              "      <td>0.332230</td>\n",
              "      <td>0.325925</td>\n",
              "      <td>0.329387</td>\n",
              "      <td>0.333160</td>\n",
              "      <td>0.327799</td>\n",
              "      <td>0.319943</td>\n",
              "      <td>0.317603</td>\n",
              "      <td>0.326645</td>\n",
              "      <td>0.328819</td>\n",
              "      <td>0.315980</td>\n",
              "      <td>0.302303</td>\n",
              "      <td>0.298552</td>\n",
              "      <td>0.304833</td>\n",
              "      <td>0.296585</td>\n",
              "      <td>0.276508</td>\n",
              "      <td>22</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Searching for Bobby Fischer</td>\n",
              "      <td>calmness</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.720999</td>\n",
              "      <td>0.824642</td>\n",
              "      <td>0.701456</td>\n",
              "      <td>0.629354</td>\n",
              "      <td>0.548922</td>\n",
              "      <td>0.707850</td>\n",
              "      <td>0.731817</td>\n",
              "      <td>0.670715</td>\n",
              "      <td>0.626261</td>\n",
              "      <td>0.608348</td>\n",
              "      <td>0.805158</td>\n",
              "      <td>0.699980</td>\n",
              "      <td>0.760697</td>\n",
              "      <td>0.756772</td>\n",
              "      <td>0.729119</td>\n",
              "      <td>0.823306</td>\n",
              "      <td>0.760343</td>\n",
              "      <td>0.721423</td>\n",
              "      <td>0.744670</td>\n",
              "      <td>0.850936</td>\n",
              "      <td>0.867150</td>\n",
              "      <td>0.756477</td>\n",
              "      <td>0.596873</td>\n",
              "      <td>0.656294</td>\n",
              "      <td>0.853543</td>\n",
              "      <td>0.726749</td>\n",
              "      <td>0.671016</td>\n",
              "      <td>0.519910</td>\n",
              "      <td>0.669217</td>\n",
              "      <td>0.780624</td>\n",
              "      <td>0.573094</td>\n",
              "      <td>0.505563</td>\n",
              "      <td>0.536576</td>\n",
              "      <td>0.578516</td>\n",
              "      <td>0.559275</td>\n",
              "      <td>0.457948</td>\n",
              "      <td>0.411667</td>\n",
              "      <td>0.375157</td>\n",
              "      <td>0.526581</td>\n",
              "      <td>...</td>\n",
              "      <td>0.485009</td>\n",
              "      <td>0.447577</td>\n",
              "      <td>0.438965</td>\n",
              "      <td>0.443438</td>\n",
              "      <td>0.438332</td>\n",
              "      <td>0.420980</td>\n",
              "      <td>0.392611</td>\n",
              "      <td>0.379576</td>\n",
              "      <td>0.363888</td>\n",
              "      <td>0.354684</td>\n",
              "      <td>0.351318</td>\n",
              "      <td>0.320224</td>\n",
              "      <td>0.334789</td>\n",
              "      <td>0.346021</td>\n",
              "      <td>0.342594</td>\n",
              "      <td>0.321363</td>\n",
              "      <td>0.313929</td>\n",
              "      <td>0.320664</td>\n",
              "      <td>0.326143</td>\n",
              "      <td>0.317346</td>\n",
              "      <td>0.304665</td>\n",
              "      <td>0.306543</td>\n",
              "      <td>0.308382</td>\n",
              "      <td>0.306202</td>\n",
              "      <td>0.300586</td>\n",
              "      <td>0.291296</td>\n",
              "      <td>0.290441</td>\n",
              "      <td>0.289939</td>\n",
              "      <td>22</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>D.O.A.</td>\n",
              "      <td>surprise</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.716593</td>\n",
              "      <td>0.817322</td>\n",
              "      <td>0.703663</td>\n",
              "      <td>0.635128</td>\n",
              "      <td>0.549264</td>\n",
              "      <td>0.698792</td>\n",
              "      <td>0.725657</td>\n",
              "      <td>0.675416</td>\n",
              "      <td>0.631039</td>\n",
              "      <td>0.604536</td>\n",
              "      <td>0.796221</td>\n",
              "      <td>0.700781</td>\n",
              "      <td>0.766376</td>\n",
              "      <td>0.756215</td>\n",
              "      <td>0.719793</td>\n",
              "      <td>0.815470</td>\n",
              "      <td>0.762701</td>\n",
              "      <td>0.724979</td>\n",
              "      <td>0.743327</td>\n",
              "      <td>0.846702</td>\n",
              "      <td>0.868651</td>\n",
              "      <td>0.761658</td>\n",
              "      <td>0.599035</td>\n",
              "      <td>0.653700</td>\n",
              "      <td>0.849689</td>\n",
              "      <td>0.731988</td>\n",
              "      <td>0.678717</td>\n",
              "      <td>0.520605</td>\n",
              "      <td>0.660331</td>\n",
              "      <td>0.777091</td>\n",
              "      <td>0.579415</td>\n",
              "      <td>0.509069</td>\n",
              "      <td>0.532065</td>\n",
              "      <td>0.572715</td>\n",
              "      <td>0.560654</td>\n",
              "      <td>0.462680</td>\n",
              "      <td>0.410195</td>\n",
              "      <td>0.368465</td>\n",
              "      <td>0.522799</td>\n",
              "      <td>...</td>\n",
              "      <td>0.425658</td>\n",
              "      <td>0.417648</td>\n",
              "      <td>0.405843</td>\n",
              "      <td>0.394956</td>\n",
              "      <td>0.385626</td>\n",
              "      <td>0.387274</td>\n",
              "      <td>0.378654</td>\n",
              "      <td>0.362965</td>\n",
              "      <td>0.343049</td>\n",
              "      <td>0.343962</td>\n",
              "      <td>0.363006</td>\n",
              "      <td>0.334972</td>\n",
              "      <td>0.310222</td>\n",
              "      <td>0.308233</td>\n",
              "      <td>0.291096</td>\n",
              "      <td>0.279795</td>\n",
              "      <td>0.281575</td>\n",
              "      <td>0.284084</td>\n",
              "      <td>0.274219</td>\n",
              "      <td>0.263598</td>\n",
              "      <td>0.266709</td>\n",
              "      <td>0.265663</td>\n",
              "      <td>0.255200</td>\n",
              "      <td>0.245400</td>\n",
              "      <td>0.243748</td>\n",
              "      <td>0.253295</td>\n",
              "      <td>0.250620</td>\n",
              "      <td>0.233153</td>\n",
              "      <td>22</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>The Hangover</td>\n",
              "      <td>amusement</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.720999</td>\n",
              "      <td>0.828911</td>\n",
              "      <td>0.705207</td>\n",
              "      <td>0.629726</td>\n",
              "      <td>0.547212</td>\n",
              "      <td>0.706456</td>\n",
              "      <td>0.733239</td>\n",
              "      <td>0.672870</td>\n",
              "      <td>0.626792</td>\n",
              "      <td>0.607395</td>\n",
              "      <td>0.805414</td>\n",
              "      <td>0.702183</td>\n",
              "      <td>0.761833</td>\n",
              "      <td>0.755288</td>\n",
              "      <td>0.728290</td>\n",
              "      <td>0.823812</td>\n",
              "      <td>0.758414</td>\n",
              "      <td>0.718713</td>\n",
              "      <td>0.743831</td>\n",
              "      <td>0.853832</td>\n",
              "      <td>0.871904</td>\n",
              "      <td>0.756891</td>\n",
              "      <td>0.594379</td>\n",
              "      <td>0.655097</td>\n",
              "      <td>0.858879</td>\n",
              "      <td>0.730417</td>\n",
              "      <td>0.671016</td>\n",
              "      <td>0.519388</td>\n",
              "      <td>0.668230</td>\n",
              "      <td>0.783274</td>\n",
              "      <td>0.576650</td>\n",
              "      <td>0.507087</td>\n",
              "      <td>0.536772</td>\n",
              "      <td>0.580116</td>\n",
              "      <td>0.561245</td>\n",
              "      <td>0.457088</td>\n",
              "      <td>0.410379</td>\n",
              "      <td>0.377457</td>\n",
              "      <td>0.529523</td>\n",
              "      <td>...</td>\n",
              "      <td>0.506221</td>\n",
              "      <td>0.471713</td>\n",
              "      <td>0.443245</td>\n",
              "      <td>0.439709</td>\n",
              "      <td>0.452884</td>\n",
              "      <td>0.451591</td>\n",
              "      <td>0.416420</td>\n",
              "      <td>0.383420</td>\n",
              "      <td>0.371029</td>\n",
              "      <td>0.385440</td>\n",
              "      <td>0.388557</td>\n",
              "      <td>0.342209</td>\n",
              "      <td>0.333697</td>\n",
              "      <td>0.345470</td>\n",
              "      <td>0.349370</td>\n",
              "      <td>0.325835</td>\n",
              "      <td>0.301585</td>\n",
              "      <td>0.305487</td>\n",
              "      <td>0.314131</td>\n",
              "      <td>0.308602</td>\n",
              "      <td>0.296613</td>\n",
              "      <td>0.289963</td>\n",
              "      <td>0.296550</td>\n",
              "      <td>0.302059</td>\n",
              "      <td>0.316022</td>\n",
              "      <td>0.311127</td>\n",
              "      <td>0.292331</td>\n",
              "      <td>0.288289</td>\n",
              "      <td>22</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>The Ring</td>\n",
              "      <td>fear</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.721733</td>\n",
              "      <td>0.825557</td>\n",
              "      <td>0.699912</td>\n",
              "      <td>0.627119</td>\n",
              "      <td>0.547725</td>\n",
              "      <td>0.706688</td>\n",
              "      <td>0.728500</td>\n",
              "      <td>0.667581</td>\n",
              "      <td>0.624491</td>\n",
              "      <td>0.606442</td>\n",
              "      <td>0.802605</td>\n",
              "      <td>0.698177</td>\n",
              "      <td>0.758425</td>\n",
              "      <td>0.753618</td>\n",
              "      <td>0.727254</td>\n",
              "      <td>0.822548</td>\n",
              "      <td>0.757985</td>\n",
              "      <td>0.718713</td>\n",
              "      <td>0.743999</td>\n",
              "      <td>0.852496</td>\n",
              "      <td>0.866900</td>\n",
              "      <td>0.755440</td>\n",
              "      <td>0.596707</td>\n",
              "      <td>0.655695</td>\n",
              "      <td>0.852060</td>\n",
              "      <td>0.726487</td>\n",
              "      <td>0.670802</td>\n",
              "      <td>0.519040</td>\n",
              "      <td>0.668724</td>\n",
              "      <td>0.781508</td>\n",
              "      <td>0.571711</td>\n",
              "      <td>0.503125</td>\n",
              "      <td>0.534419</td>\n",
              "      <td>0.578916</td>\n",
              "      <td>0.560063</td>\n",
              "      <td>0.455797</td>\n",
              "      <td>0.409091</td>\n",
              "      <td>0.375366</td>\n",
              "      <td>0.527842</td>\n",
              "      <td>...</td>\n",
              "      <td>0.519274</td>\n",
              "      <td>0.458197</td>\n",
              "      <td>0.465761</td>\n",
              "      <td>0.503463</td>\n",
              "      <td>0.488199</td>\n",
              "      <td>0.434222</td>\n",
              "      <td>0.401970</td>\n",
              "      <td>0.399569</td>\n",
              "      <td>0.399155</td>\n",
              "      <td>0.375705</td>\n",
              "      <td>0.343164</td>\n",
              "      <td>0.323228</td>\n",
              "      <td>0.350348</td>\n",
              "      <td>0.355537</td>\n",
              "      <td>0.325518</td>\n",
              "      <td>0.296369</td>\n",
              "      <td>0.308732</td>\n",
              "      <td>0.331301</td>\n",
              "      <td>0.325239</td>\n",
              "      <td>0.302044</td>\n",
              "      <td>0.340447</td>\n",
              "      <td>0.305278</td>\n",
              "      <td>0.279362</td>\n",
              "      <td>0.297673</td>\n",
              "      <td>0.317099</td>\n",
              "      <td>0.305071</td>\n",
              "      <td>0.281224</td>\n",
              "      <td>0.278040</td>\n",
              "      <td>22</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>300</td>\n",
              "      <td>excitement</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 107533 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Electrode1_1  Electrode1_2  ...  class  valencehigh  arousalhigh\n",
              "0           0      0.711454      0.816407  ...      3            1            1\n",
              "1           1      0.720999      0.824642  ...      0            1            1\n",
              "2           2      0.716593      0.817322  ...      0            1            1\n",
              "3           3      0.720999      0.828911  ...      1            1            1\n",
              "4           4      0.721733      0.825557  ...      0            1            1\n",
              "\n",
              "[5 rows x 107533 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY4CY9M5HmvA"
      },
      "source": [
        "## SOME CHECKS\n",
        "# print( type(data))\n",
        "#data = pd.read_csv(\"ml_data.csv\")  \n",
        "#data_ = data.head()  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYiN_a6EfT9E"
      },
      "source": [
        "#DATA PREP FOR VALENCE\n",
        "\n",
        "#data  - ml_data.csv\n",
        "#data2 - ml_data_untouched.csv\n",
        "#Valence is judged by alphas of F3 and F4\n",
        "#F3 is data 3, F4 is data 12\n",
        "\n",
        "#df1=data2.reset_index()['psdalpha_12']\n",
        "#df2=data2.reset_index()['psdalpha_3']\n",
        "#df1 = np.array(df1, dtype = float)\n",
        "#df2 = np.array(df2, dtype = float)\n",
        "#df3 = np.concatenate((df1, df2), axis=0)\n",
        "#data2=data2.reset_index()\n",
        "dfz=data2.iloc[:,1:43]\n",
        "#dfy=pd.DataFrame(data={ 'alpha12':df1,'alpha3':df2})\n",
        "#df1 = df1.append(df2)\n",
        "dfz = np.array(dfz, dtype = float)\n",
        "dfz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6bRYlgXuP45"
      },
      "source": [
        "target=data2['valencehigh']\n",
        "#target = target.append(target)\n",
        "target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5fSvH3gvKMD"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#df1 = np.array(df1, dtype = float)\n",
        "#df2 = np.array(df2, dtype = float)\n",
        "target = np.array(target, dtype = float)\n",
        "\n",
        "\n",
        "x_Train, x_Test, y_Train, y_Test = train_test_split(dfz, target, test_size = 0.35, random_state = 6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9os0YpZ8IhwA"
      },
      "source": [
        "x_Train = x_Train.reshape(x_Train.shape[0],1,42)\n",
        "x_Test = x_Test.reshape(x_Test.shape[0],1,42)\n",
        "x_Test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxNjvs3QITTf"
      },
      "source": [
        "import tensorflow.keras.layers as KL\n",
        "inputs = KL.Input(shape=(1,42))\n",
        "x = KL.LSTM(units = 8, activation = 'relu')(inputs)\n",
        "outputs = KL.Dense(units=1, activation= 'sigmoid')(x)\n",
        "\n",
        "model = tf.keras.models.Model(inputs, outputs)\n",
        "\n",
        "opt = tf.keras.optimizers.Adamax()\n",
        "model.compile( optimizer=opt , loss='binary_crossentropy', metrics = ['accuracy'])\n",
        "history = model.fit(x_Train, y_Train, batch_size=20, epochs=1000, class_weight={0:1, 1:2},validation_data =(x_Test,y_Test))\n",
        "\n",
        "#y_pred = model.predict(x_Test)\n",
        "#print(y_pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RiAIH_ELCnd"
      },
      "source": [
        "#from sklearn.metrics import confusion_matrix, classification_report,mean_squared_error\n",
        "#confudf = pd.DataFrame(confusion_matrix(y_Test,y_pred), index = [\"Negative (Actual)\",\"Positive (Actual)\"], columns=['Negative (Predicted)', 'Postive (Predicted)'])\n",
        "#text = np.asarray([['True Negative', 'False Positive'], ['False Negative', 'True Positive']])\n",
        "#labels = (np.asarray([\"{0}\\n{1:.2f}\".format(text,data) for text, data in zip(text.flatten(), confusion_matrix(y_Test,y_pred).flatten())])).reshape(2,2)\n",
        "\n",
        "\n",
        "#sns.heatmap(confudf, annot = labels, center=100, fmt='', linewidth = '1', vmax=300, cmap = \"Blues\", cbar=False)\n",
        "\n",
        "#plt.yticks(rotation = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clJ3o2udvkVg"
      },
      "source": [
        "#model for Valence -LSTM\n",
        "\n",
        "#x_Train = x_Train.reshape(x_Train.shape[0],1,1)\n",
        "#x_Test = x_Test.reshape(x_Test.shape[0],1,1)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128,activation = 'relu', return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(64,activation ='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(32,activation ='relu'))\n",
        "model.add(Dense(2,activation ='sigmoid'))\n",
        "y_pred = model.predict(x_Test)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-3, decay=1e-5)\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer =opt,metrics=['accuracy'])\n",
        "#model.compile(loss='binary_crossentropy',optimizer =opt,metrics=['accuracy'])\n",
        "history = model.fit(x_Train,y_Train,batch_size=16,epochs=200, validation_data =(x_Test,y_Test))\n",
        "#print(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtWP9RGGflIE"
      },
      "source": [
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQq3sWvQDbsZ"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1G3EEiaBA5k-"
      },
      "source": [
        "#Alternate model for Valence - CNN\n",
        "\n",
        "#x_Train = x_Train.reshape(x_Train.shape[0],1,1)\n",
        "#x_Test = x_Test.reshape(x_Test.shape[0],1,1)\n",
        "\n",
        "model = Sequential()\n",
        "#model.add(tf.keras.layers.Flatten())\n",
        "model.add(Dense(128,activation =tf.nn.relu))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(128,activation =tf.nn.relu))\n",
        "model.add(Dense(10,activation =tf.nn.softmax))\n",
        "\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-3, decay=1e-5)\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer =opt ,metrics=['accuracy'])\n",
        "history_CNN = model.fit(x_Train,y_Train,epochs=100, validation_data =(x_Test,y_Test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr4KO1o5GFcz"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iet2OXe_zYiL"
      },
      "source": [
        " plt.plot(history.history['loss'])\n",
        " plt.show()\n",
        " plt.plot(history_CNN.history['loss'])\n",
        " plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dio3bwThAmNN"
      },
      "source": [
        "#DATA PREP FOR AROUSAL\n",
        "\n",
        "#Arousal is judged by alpha beta ratio of AF3 and AF4\n",
        "#AF3 is data 1, AF4 is data 14\n",
        "df3=data2.reset_index()['psdalpha_1']\n",
        "df4=data2.reset_index()['psdbeta_1']\n",
        "\n",
        "df34 = df4/df3\n",
        "\n",
        "df5=data2.reset_index()['psdalpha_14']\n",
        "df6=data2.reset_index()['psdbeta_14']\n",
        "\n",
        "df56  = df5/df6\n",
        "\n",
        "df7 = df34.append(df56)\n",
        "df7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-BHZvhEBbQ7"
      },
      "source": [
        "target2 =data2['arousalhigh']\n",
        "#target2 = target2.append(target2)\n",
        "target2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhXGiNKmB4YN"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#df7 = np.array(df7, dtype = float)\n",
        "target2 = np.array(target2, dtype = float)\n",
        "x_Train2, x_Test2, y_Train2, y_Test2 = train_test_split(dfz, target2, test_size = 0.35, random_state = 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsPF5WXmaoKo"
      },
      "source": [
        "x_Train2 = x_Train2.reshape(x_Train2.shape[0],1,42)\n",
        "x_Test2 = x_Test2.reshape(x_Test2.shape[0],1,42)\n",
        "x_Test2.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-55ywpyCEEV"
      },
      "source": [
        "#model for Arousal\n",
        "\n",
        "#x_Train2 = x_Train2.reshape(x_Train2.shape[0],1,1)\n",
        "#x_Test2 = x_Test2.reshape(x_Test2.shape[0],1,1)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128,activation = 'relu', return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128,activation ='relu'))\n",
        "model.add(Dense(32,activation ='relu'))\n",
        "model.add(Dense(10,activation ='softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-3, decay=1e-5)\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer =opt,metrics=['accuracy'])\n",
        "history = model.fit(x_Train2,y_Train2,epochs=1000, validation_data =(x_Test2,y_Test2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buc3NgChDNXI"
      },
      "source": [
        " plt.plot(history.history['loss'])\n",
        " plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT9V5X3eG1FT"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deXLF_lVMzHg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}